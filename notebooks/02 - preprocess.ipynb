{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2500bb76-d009-4648-8bb7-84a3db287a13",
   "metadata": {},
   "source": [
    "# Monitoring ML Training Pipeline: Preprocessing\n",
    "- Load extracted raw data\n",
    "- Enforce datatypes\n",
    "- Engineer new features\n",
    "- Split train-test\n",
    "- Train transformation models for\n",
    "    - Imputing missing values\n",
    "    - Converting categorical to numerical values\n",
    "    - Rescaling\n",
    "- Apply the transformation models on both training and test datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d036ca6c-84e2-4a69-ba01-fbd51a4769ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'dags', 'src'))\n",
    "\n",
    "import helpers\n",
    "import config\n",
    "\n",
    "reload(helpers)\n",
    "reload(config)\n",
    "\n",
    "engineered_vars = {\n",
    "    \"categorical\": [\"application_year\", \"application_month\", \"application_week\", \"application_day\", \"application_season\"],\n",
    "    \"numerical\": [\"current_credit_balance_ratio\"],\n",
    "    \"date\": [\"application_date\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57448c20-813e-40e3-b5b0-bd96fc1fded9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64ac252b-a013-450a-9937-10b9538ec4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### helpers.py methods ####\n",
    "\n",
    "def save_dataset(df: pd.DataFrame, path: str):\n",
    "    \"\"\"\n",
    "    Save data set.\n",
    "    :param df: DataFrame - The DataFrame to be saved.\n",
    "    :param path: str - The file path to save the data.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    df.to_csv(path, index=False)  # Save the DataFrame to a CSV file without including the index.\n",
    "    print(f\"[INFO] Dataset saved to {path}\")  # Print a message confirming the dataset has been saved.\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data set.\n",
    "    :param path: str - The file path to load the data from.\n",
    "    :return: DataFrame - The loaded DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(path)  # Load a DataFrame from the specified CSV file.\n",
    "\n",
    "def save_model_as_pickle(model, model_name: str, directory=None):\n",
    "    \"\"\"\n",
    "    Save a model as a pickle file.\n",
    "    :param model: AnyType - The model to be saved.\n",
    "    :param model_name: str - The name of the model.\n",
    "    :param directory: str - The directory to save the model (optional).\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if directory:\n",
    "        filename = os.path.join(directory, model_name + \".pkl\")\n",
    "    else:\n",
    "        filename = os.path.join(config.PATH_DIR_MODELS, model_name + \".pkl\")\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)  # Serialize and save the model as a pickle file.\n",
    "    print(\"[INFO] Model saved as pickle file:\", filename)  # Print a message confirming the model has been saved.\n",
    "\n",
    "def load_model_from_pickle(model_name: str):\n",
    "    \"\"\"\n",
    "    Load a pickle model.\n",
    "    :param model_name: str - The name of the model to load.\n",
    "    :return: AnyType - The loaded model.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(config.PATH_DIR_MODELS, model_name + \".pkl\"), \"rb\") as f:\n",
    "        return pickle.load(f)  # Deserialize and load a model from a pickle file.\n",
    "\n",
    "def save_model_as_json(model: dict, model_name: str, directory: str = None):\n",
    "    \"\"\"\n",
    "    Save a model as a JSON file.\n",
    "    :param model: dict - The model to be saved as a JSON file.\n",
    "    :param model_name: str - The name of the model.\n",
    "    :param directory: str - The directory to save the model (optional).\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if directory:\n",
    "        filename = os.path.join(directory, model_name + \".json\")\n",
    "    else:\n",
    "        filename = os.path.join(config.PATH_DIR_MODELS, model_name + \".json\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(model, f)  # Serialize and save the model as a JSON file.\n",
    "    print(\"[INFO] Model saved as JSON file:\", filename)  # Print a message confirming the model has been saved.\n",
    "\n",
    "def load_model_from_json(model_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load a JSON model.\n",
    "    :param model_name: str - The name of the model to load.\n",
    "    :return: dict - The loaded model as a dictionary.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(config.PATH_DIR_MODELS, model_name + \".json\"), \"r\") as f:\n",
    "        return json.load(f)  # Deserialize and load a model from a JSON file as a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d8af5ed-7bbe-441e-8158-78e1e5c1b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### preprocess.py methods #####\n",
    "\n",
    "###### missing values ######\n",
    "\n",
    "def get_variables_with_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get variables with missing values.\n",
    "    :param df: DataFrame\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    missing_counts = df.isnull().sum()\n",
    "    return missing_counts[missing_counts > 0].index.tolist()\n",
    "\n",
    "def impute_missing_values(df: pd.DataFrame, method: str = \"basic\", mode: str = None,\n",
    "                          cat_vars: list = config.CAT_VARS, num_vars: list = config.NUM_VARS, job_id: str = \"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Treat missing values.\n",
    "    \n",
    "    :param df: DataFrame - The DataFrame with missing values.\n",
    "    :param method: str, \"basic\" or \"advanced\" - The imputation method to use.\n",
    "    :param mode: str, \"training\" or \"inference\" - The mode of operation (training or inference).\n",
    "    :return: DataFrame - The DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    assert mode in (\"training\", \"inference\"), f\"mode must be either 'training' or 'inference, but got {mode}\"\n",
    "    assert method in [\"basic\", \"advanced\"], f\"{method} is not a valid method (basic, advanced)\"\n",
    "    \n",
    "    if mode == \"training\":\n",
    "        model = {\n",
    "            \"method\": method,\n",
    "            \"imputes\": dict()\n",
    "        }\n",
    "        for col in df.columns:\n",
    "            print(\"[INFO] Treating missing values in column:\", col)\n",
    "            model[\"imputes\"][col] = dict()\n",
    "            if method == \"basic\":\n",
    "                if col in set(cat_vars + engineered_vars[\"categorical\"]):\n",
    "                    model[\"imputes\"][col]['mode'] = df[df[col].notnull()][col].mode()[0]\n",
    "                elif col in set(num_vars + engineered_vars[\"numerical\"]):\n",
    "                    model[\"imputes\"][col]['mean'] = df[df[col].notnull()][col].mean()\n",
    "                elif col in set(config.DATETIME_VARS + engineered_vars[\"date\"]):\n",
    "                    model[\"imputes\"][col]['mode'] = df[df[col].notnull()][col].mode()[0]\n",
    "                elif col in [\"loan_id\", \"customer_id\", \"loan_status\"] + config.EXC_VARIABLES:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(f\"[ERROR]{col} is not a valid variable\")\n",
    "        helpers.save_model_as_pickle(model, f\"{job_id}_missing_values_model\")\n",
    "        return impute_missing_values(df, method=method, mode=\"inference\", cat_vars=cat_vars, num_vars=num_vars, job_id=job_id)\n",
    "    else:\n",
    "        model = helpers.load_model_from_pickle(model_name=f\"{job_id}_missing_values_model\")\n",
    "        cols = get_variables_with_missing_values(df)\n",
    "        method = model[\"method\"]\n",
    "        if method == \"basic\":\n",
    "            for col in cols:\n",
    "                if col in set(cat_vars + engineered_vars[\"categorical\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mode'], inplace=True)\n",
    "                elif col in set(num_vars + engineered_vars[\"numerical\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mean'], inplace=True)\n",
    "                elif col in set(config.DATETIME_VARS + engineered_vars[\"date\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mode'], inplace=True)\n",
    "                elif col in [\"loan_id\", \"customer_id\", \"loan_status\"] + config.EXC_VARIABLES:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(f\"[ERROR]{col} is not a valid variable. Pre-trained variables: {list(model['imputes'].keys())}\")\n",
    "        if method == \"advanced\":\n",
    "            raise NotImplementedError\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "495d6324-d93f-4b19-b85a-a920383166b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### enforcing datatypes ######\n",
    "\n",
    "def enforce_datatypes_on_variables(df: pd.DataFrame, cat_vars: list = [], num_vars: list = []) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform variables.\n",
    "    :param df: DataFrame - The DataFrame to transform.\n",
    "    :param cat_vars: list - List of categorical variables.\n",
    "    :param num_vars: list - List of numerical variables.\n",
    "    :return: DataFrame - The transformed DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"application_time\"] = pd.to_datetime(df[\"application_time\"])  # Convert the \"application_time\" column to datetime.\n",
    "    for var in num_vars:\n",
    "        df[var] = df[var].apply(lambda x: enforce_numeric_to_float(x))  # Apply the helper function to enforce numeric to float for numerical variables.\n",
    "    for var in cat_vars:\n",
    "        df[var] = df[var].astype(str)  # Convert categorical variables to strings.\n",
    "    return df\n",
    "\n",
    "def enforce_numeric_to_float(x: str) -> float:\n",
    "    \"\"\"\n",
    "    Convert numeric to float. To ensure that all stringified numbers are converted to float.\n",
    "    :param x: str - The string to convert to float.\n",
    "    :return: float - The converted float value.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(re.sub(\"[^0-9.]\", \"\", str(x)))  # Convert the string to a float, removing non-numeric characters.\n",
    "    except ValueError:\n",
    "        return np.nan  # Return NaN if conversion is not possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a71b3527-8eb7-4796-833e-97f9c1c3762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### encoding categorical variables ######\n",
    "\n",
    "# Function to categorize years in current job\n",
    "def categorize_years_in_current_job(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Categorize years in current job.\n",
    "    :param x: str\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    \n",
    "# Function to convert term to integer\n",
    "def term_to_int(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert term to int.\n",
    "    :param x: str, lower cased term\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    \n",
    "# Function to convert home ownership to integer\n",
    "def home_ownership_to_int(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert home ownership to int.\n",
    "    :param x: str, lower cased home ownership\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    \n",
    "# Function to train a model for converting purpose to int\n",
    "def train_purpose_to_int_model(x: pd.Series, method: str, job_id: str = \"\") -> dict:\n",
    "    \"\"\"\n",
    "    Build a model file to be used to convert string variable `purpose` into integer datatype.\n",
    "    :param x: pd.Series\n",
    "    :param method: str, \"ranking\", \"weighted ranking\", \"relative ranking\"\n",
    "    :param job_id: str, job id\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "    \n",
    "# Function to convert purpose to int\n",
    "def purpose_to_int(x: pd.Series, mode: str, method: str = None, model: str = None, job_id: str = \"\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert purpose to int.\n",
    "    :param x: pd.Series\n",
    "    :param mode: str, choose from \"training\", \"inference\"\n",
    "    :param method: str, \"ranking\", \"weighted ranking\", \"relative ranking\"\n",
    "    :param model: method, model to predict the purpose\n",
    "    :param job_id: str, job id\n",
    "    :return: pd.Series\n",
    "    \"\"\"\n",
    "    \n",
    "# Function to convert loan status to int\n",
    "def loan_status_to_int(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert loan status to int.\n",
    "    :param x: str, lower cased loan status\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    \n",
    "# Function to encode categorical variables in a DataFrame\n",
    "def encode_categorical_variables(df: pd.DataFrame, mode=\"training\", purpose_encode_method=\"ranking\", job_id: str = \"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode categorical variables.\n",
    "    :param df: DataFrame\n",
    "    :param mode: str, \"training\" or \"inference\"\n",
    "    :param purpose_encode_method: str, choose from \"ranking\", \"weighted ranking\", \"relative ranking\"\n",
    "    :param job_id: str, job id\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66396d4a-c68e-447a-b125-df974fd6b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### engineer new variables ######\n",
    "\n",
    "def engineer_variables(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Engineer variables.\n",
    "    :param df: DataFrame\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    for col in [\"application_time\"]:\n",
    "        assert col in df.columns, f\"{col} not in {df.columns}\"\n",
    "\n",
    "    df[\"application_date\"] = df[\"application_time\"].dt.date\n",
    "    df[\"application_year\"] = df[\"application_time\"].dt.year\n",
    "    df[\"application_month\"] = df[\"application_time\"].dt.month\n",
    "    df[\"application_week\"] = df[\"application_time\"].dt.week\n",
    "    df[\"application_day\"] = df[\"application_time\"].dt.day\n",
    "    df[\"application_season\"] = df[\"application_month\"].apply(lambda x: month_to_season(x))\n",
    "    df[\"current_credit_balance_ratio\"] = (df[\"current_credit_balance\"] / df[\"current_loan_amount\"]).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "def month_to_season(month: int) -> int:\n",
    "    \"\"\"\n",
    "    Convert date to season.\n",
    "    :param month: int, month between 1 and 12\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    if month in [1, 2, 3]:\n",
    "        return 1\n",
    "    elif month in [4, 5, 6]:\n",
    "        return 2\n",
    "    elif month in [7, 8, 9]:\n",
    "        return 3\n",
    "    elif month in [10, 11, 12]:\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a800973c-51d4-4f63-ab48-901ceb32741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data transformation ####\n",
    "def rescale_data(df: pd.DataFrame, method: str = 'standardize', mode: str = 'training', columns: list = [], job_id: str = \"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rescale data.\n",
    "    :param df: DataFrame\n",
    "    :param method: str, 'standardize' or 'minmax'\n",
    "    :param mode: str, 'training' or 'inference'\n",
    "    :param columns: list of columns to rescale\n",
    "    :param job_id: a job identifier\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    # Check if the rescaling method is valid (either 'standardize' or 'minmax')\n",
    "    assert method in ('standardize', 'minmax'), f\"{method} is not a valid method (standardize, minmax)\"\n",
    "    \n",
    "    # Check if the mode is valid (either 'training' or 'inference')\n",
    "    assert mode in ('training', 'inference'), f\"{mode} is not a valid mode (training, inference)\"\n",
    "    \n",
    "    # Check if specified columns exist in the DataFrame\n",
    "    for col in columns:\n",
    "        assert col in df.columns\n",
    "\n",
    "    if mode == 'training':\n",
    "        if method == 'standardize':\n",
    "            # Create a StandardScaler object and fit it to the training data\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df[columns])\n",
    "        if method == 'minmax':\n",
    "            # Create a MinMaxScaler object and fit it to the training data\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(df[columns])\n",
    "        \n",
    "        # Create a model dictionary with the scaler and method\n",
    "        model = {\n",
    "            'scaler': scaler,\n",
    "            'method': method,\n",
    "        }\n",
    "        \n",
    "        # Save the model using a custom function (not shown in the provided code)\n",
    "        helpers.save_model_as_pickle(model, f\"{config.PATH_DIR_MODELS}/{job_id}_numerical_scaler.pkl\")\n",
    "        \n",
    "        # Transform the specified columns in the DataFrame and add them with new names\n",
    "        df[list(map(lambda x: f\"{method}_{x}\", columns))] = scaler.transform(df[columns])\n",
    "        return df\n",
    "\n",
    "    if mode == 'inference':\n",
    "        # Load the model using a custom function (not shown in the provided code)\n",
    "        model = helpers.load_model_from_pickle(model_name=f\"{job_id}_numerical_scaler.pkl\")\n",
    "        scaler = model['scaler']\n",
    "        method = model['method']\n",
    "        \n",
    "        # Attempt to convert the specified columns to float (debugging purpose)\n",
    "        for col in columns:\n",
    "            try:\n",
    "                df[col].astype(float)\n",
    "            except:\n",
    "                print(\"[DEBUG] Column skipped:\", col)\n",
    "        \n",
    "        # Transform the specified columns in the DataFrame and add them with new names\n",
    "        df[list(map(lambda x: f\"{method}_{x}\", columns))] = scaler.transform(df[columns])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63abd0a6-9a34-4ffb-bf89-47fe5062dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Preprocess ######\n",
    "\n",
    "# Function to split data into train and test based on the method provided\n",
    "def split_train_test(df: pd.DataFrame, test_size: float, method: str = 'time based'):\n",
    "    \"\"\"\n",
    "    Split data into train and test.\n",
    "    :param df: DataFrame\n",
    "    :param test_size: float, between 0 and 0.99\n",
    "    :param method: str, 'time based' or 'random'\n",
    "    :return: (DataFrame, DataFrame)\n",
    "    \"\"\"\n",
    "    if method == 'random':\n",
    "        # Randomly shuffle and split the DataFrame into train and test\n",
    "        return df.sample(frac=1, random_state=config.RANDOM_STATE).iloc[:int(len(df) * test_size)], df.sample(frac=1, random_state=config.RANDOM_STATE).iloc[int(len(df) * test_size):]\n",
    "    if method == 'time based':\n",
    "        # Split based on time order of dates in the 'application_date' column\n",
    "        unique_dates = sorted(df[\"application_date\"].unique())\n",
    "        train_dates = unique_dates[:int(len(unique_dates) * (1 - test_size))]\n",
    "        test_dates = unique_dates[unique_dates.index(train_dates[-1]) + 1:]\n",
    "        train_df = df[df[\"application_date\"].isin(train_dates)]\n",
    "        test_df = df[df[\"application_date\"].isin(test_dates)]\n",
    "        return train_df, test_df\n",
    "    raise ValueError(f\"{method} is not a valid method (time based, random)\")\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(df: pd.DataFrame, mode: str, job_id: str = None, rescale: bool = False, ref_job_id: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pre-process data and save preprocessed datasets for later use.\n",
    "    :param df: DataFrame\n",
    "    :param mode: str, 'training' or 'inference'\n",
    "    :param job_id: str, job_id for the preprocessed dataset\n",
    "    :param rescale: bool, whether to rescale data.\n",
    "    :param ref_job_id: str, job_id of the last deployed model. Useful when doing inference.\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    assert mode in ('training', 'inference')\n",
    "    \n",
    "    if mode == 'training':\n",
    "        assert config.TARGET in df.columns, f\"{config.TARGET} not in {df.columns}\"\n",
    "    \n",
    "    # Convert column names to lowercase\n",
    "    df.columns = list(map(str.lower, df.columns))\n",
    "    initial_size = df.shape[0]\n",
    "    \n",
    "    # Remove rows with null values in specific columns\n",
    "    df = df[df[\"customer_id\"].notnull() & df[\"loan_id\"].notnull() & df[\"loan_status\"].notnull()]\n",
    "    \n",
    "    if mode == 'training':\n",
    "        df[\"loan_status\"] = df[\"loan_status\"].str.lower()\n",
    "    \n",
    "    if df.shape[0] != initial_size:\n",
    "        print(f\"[WARNING] Dropped {initial_size - df.shape[0]} rows with null values in (customer_id, loan_id, loan_status)\")\n",
    "    \n",
    "    # Enforce data types on variables (not shown in the code)\n",
    "    df = enforce_datatypes_on_variables(df, cat_vars=config.CAT_VARS, num_vars=config.NUM_VARS)\n",
    "    \n",
    "    # Engineer variables (not shown in the code)\n",
    "    df = engineer_variables(df)\n",
    "    \n",
    "    if mode == 'training':\n",
    "        # Split train and test data before encoding categorical variables and imputing missing values\n",
    "        train_df, test_df = split_train_test(df, config.TEST_SPLIT_SIZE, method=config.SPLIT_METHOD)\n",
    "        train_df = encode_categorical_variables(train_df, mode=\"training\", purpose_encode_method=config.PURPOSE_ENCODING_METHOD, job_id=job_id)\n",
    "        train_df = impute_missing_values(train_df, method=\"basic\", mode=\"training\", job_id=job_id)\n",
    "        \n",
    "        if rescale:\n",
    "            # Rescale data if necessary\n",
    "            train_df = rescale_data(train_df, method=config.RESCALE_METHOD, mode=\"training\", columns=num_vars + engineered_vars[\"numerical\"])\n",
    "        \n",
    "        # Save the preprocessed training dataset\n",
    "        helpers.save_dataset(train_df, os.path.join(config.PATH_DIR_DATA, \"preprocessed\", f\"{job_id}_training.csv\"))\n",
    "        \n",
    "        # Recursively preprocess the test data for inference\n",
    "        preprocess_data(test_df, mode=\"inference\", job_id=job_id, ref_job_id=job_id)\n",
    "    else:\n",
    "        # If the mode is inference, no need to split train and test data\n",
    "        test_df = encode_categorical_variables(df, mode=\"inference\", purpose_encode_method=config.PURPOSE_ENCODING_METHOD, job_id=ref_job_id)\n",
    "        test_df = impute_missing_values(test_df, method=\"basic\", mode=\"inference\", job_id=ref_job_id)\n",
    "        \n",
    "        if rescale:\n",
    "            # Rescale data if necessary\n",
    "            test_df = rescale_data(test_df, method=config.RESCALE_METHOD, mode=\"inference\", columns=num_vars + engineered_vars[\"numerical\"])\n",
    "        \n",
    "        # Save the preprocessed inference dataset\n",
    "        helpers.save_dataset(test_df, os.path.join(config.PATH_DIR_DATA, \"preprocessed\", f\"{job_id}_inference.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c19e730-1c5b-4cc5-9353-f13f6253cf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-f9a3f84c1aa4>:14: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df[\"application_week\"] = df[\"application_time\"].dt.week\n",
      "<ipython-input-21-9a9da3f58eb2>:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].str.lower()\n",
      "<ipython-input-21-9a9da3f58eb2>:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"term\"] = df[\"term\"].apply(lambda x: term_to_int(x))\n",
      "<ipython-input-21-9a9da3f58eb2>:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"home_ownership\"] = df[\"home_ownership\"].apply(lambda x: home_ownership_to_int(x))\n",
      "<ipython-input-21-9a9da3f58eb2>:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"years_in_current_job\"] = df[\"years_in_current_job\"].apply(lambda x: categorize_years_in_current_job(x))\n",
      "<ipython-input-21-9a9da3f58eb2>:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[config.TARGET.lower()] = df[config.TARGET.lower()].apply(lambda x: loan_status_to_int(x))\n",
      "<ipython-input-21-9a9da3f58eb2>:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"purpose\"] = purpose_to_int(df[\"purpose\"], mode=mode, method=purpose_encode_method, job_id=job_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting purpose to int using method: weighted ranking\n",
      "[INFO] No model for purpose-to-int conversion provided. Training a new model first...\n",
      "[INFO] Model saved as json file: ../dags/models\\aa4c3eaadb02409281b589829e3c9370_purpose_to_int_model.json\n",
      "[INFO] Treating missing values in column: loan_id\n",
      "[INFO] Treating missing values in column: customer_id\n",
      "[INFO] Treating missing values in column: loan_status\n",
      "[INFO] Treating missing values in column: application_time\n",
      "[INFO] Treating missing values in column: current_loan_amount\n",
      "[INFO] Treating missing values in column: term\n",
      "[INFO] Treating missing values in column: tax_liens\n",
      "[INFO] Treating missing values in column: purpose\n",
      "[INFO] Treating missing values in column: no_of_properties\n",
      "[INFO] Treating missing values in column: home_ownership\n",
      "[INFO] Treating missing values in column: annual_income\n",
      "[INFO] Treating missing values in column: years_in_current_job\n",
      "[INFO] Treating missing values in column: months_since_last_delinquent\n",
      "[INFO] Treating missing values in column: no_of_cars\n",
      "[INFO] Treating missing values in column: no_of_children\n",
      "[INFO] Treating missing values in column: credit_score\n",
      "[INFO] Treating missing values in column: monthly_debt\n",
      "[INFO] Treating missing values in column: years_of_credit_history\n",
      "[INFO] Treating missing values in column: no_of_open_accounts\n",
      "[INFO] Treating missing values in column: no_of_credit_problems\n",
      "[INFO] Treating missing values in column: current_credit_balance\n",
      "[INFO] Treating missing values in column: max_open_credit\n",
      "[INFO] Treating missing values in column: bankruptcies\n",
      "[INFO] Treating missing values in column: application_date\n",
      "[INFO] Treating missing values in column: application_year\n",
      "[INFO] Treating missing values in column: application_month\n",
      "[INFO] Treating missing values in column: application_week\n",
      "[INFO] Treating missing values in column: application_day\n",
      "[INFO] Treating missing values in column: application_season\n",
      "[INFO] Treating missing values in column: current_credit_balance_ratio\n",
      "[INFO] Model saved as pickle file: ../dags/models\\aa4c3eaadb02409281b589829e3c9370_missing_values_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhaga\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset saved to ../dags/data\\preprocessed\\aa4c3eaadb02409281b589829e3c9370_training.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-f9a3f84c1aa4>:14: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df[\"application_week\"] = df[\"application_time\"].dt.week\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting purpose to int using method: weighted ranking\n",
      "[INFO] No model for purpose-to-int conversion provided. Training a new model first...\n",
      "[INFO] Model saved as json file: ../dags/models\\aa4c3eaadb02409281b589829e3c9370_purpose_to_int_model.json\n",
      "[INFO] Dataset saved to ../dags/data\\preprocessed\\aa4c3eaadb02409281b589829e3c9370_inference.csv\n"
     ]
    }
   ],
   "source": [
    "# Change the filename and job ID accordingly\n",
    "filename = \"../dags/data/raw/12196ecaa65e4831987aee4bfced5f60_2015-01-01_2015-05-31.csv\"\n",
    "job_id = \"12196ecaa65e4831987aee4bfced5f60\"\n",
    "\n",
    "# Load the dataset from the new filename\n",
    "df = helpers.load_dataset(os.path.join(filename))\n",
    "\n",
    "# Preprocess the data using the new job ID and any other desired settings\n",
    "_ = preprocess_data(df=df, mode=\"training\", job_id=job_id, rescale=False, ref_job_id=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da6532ac-b039-4f4f-b8ad-c113dcdb38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed training dataset using the specified job ID\n",
    "tdf = pd.read_csv(\"../dags/data/preprocessed/12196ecaa65e4831987aee4bfced5f60_training.csv\")\n",
    "\n",
    "# Load the preprocessed inference dataset using the same job ID\n",
    "vdf = pd.read_csv(\"../dags/data/preprocessed/12196ecaa65e4831987aee4bfced5f60_inference.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "081a8373-5cab-423a-bbd3-6b138149e3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>current_loan_amount</th>\n",
       "      <td>33231.000000</td>\n",
       "      <td>15612.000000</td>\n",
       "      <td>7959.000000</td>\n",
       "      <td>29346.000000</td>\n",
       "      <td>6011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_score</th>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_in_current_job</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>0.786098</td>\n",
       "      <td>0.060076</td>\n",
       "      <td>0.060076</td>\n",
       "      <td>0.786098</td>\n",
       "      <td>0.003407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_debt</th>\n",
       "      <td>941.224573</td>\n",
       "      <td>941.224573</td>\n",
       "      <td>949.300000</td>\n",
       "      <td>941.224573</td>\n",
       "      <td>941.224573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_of_credit_history</th>\n",
       "      <td>18.560949</td>\n",
       "      <td>18.560949</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.560949</td>\n",
       "      <td>18.560949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>months_since_last_delinquent</th>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_open_accounts</th>\n",
       "      <td>11.028741</td>\n",
       "      <td>11.028741</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.028741</td>\n",
       "      <td>11.028741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_credit_problems</th>\n",
       "      <td>0.145312</td>\n",
       "      <td>0.145312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145312</td>\n",
       "      <td>0.145312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_credit_balance</th>\n",
       "      <td>15439.198372</td>\n",
       "      <td>15439.198372</td>\n",
       "      <td>4993.000000</td>\n",
       "      <td>15439.198372</td>\n",
       "      <td>15439.198372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_open_credit</th>\n",
       "      <td>40776.357186</td>\n",
       "      <td>40776.357186</td>\n",
       "      <td>14729.000000</td>\n",
       "      <td>40776.357186</td>\n",
       "      <td>40776.357186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankruptcies</th>\n",
       "      <td>0.105735</td>\n",
       "      <td>0.105735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105735</td>\n",
       "      <td>0.105735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax_liens</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_properties</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_cars</th>\n",
       "      <td>2.490606</td>\n",
       "      <td>2.490606</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.490606</td>\n",
       "      <td>2.490606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_children</th>\n",
       "      <td>1.501658</td>\n",
       "      <td>1.501658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.501658</td>\n",
       "      <td>1.501658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_year</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_month</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_week</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_day</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_season</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_credit_balance_ratio</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0             1             2  \\\n",
       "current_loan_amount           33231.000000  15612.000000   7959.000000   \n",
       "term                              0.000000      1.000000      0.000000   \n",
       "credit_score                   1350.696132   1350.696132   1350.696132   \n",
       "years_in_current_job             -1.000000     -1.000000      2.000000   \n",
       "home_ownership                    1.000000      1.000000      1.000000   \n",
       "annual_income                 71612.920399  71612.920399  71612.920399   \n",
       "purpose                           0.786098      0.060076      0.060076   \n",
       "monthly_debt                    941.224573    941.224573    949.300000   \n",
       "years_of_credit_history          18.560949     18.560949     21.000000   \n",
       "months_since_last_delinquent     34.752726     34.752726     34.752726   \n",
       "no_of_open_accounts              11.028741     11.028741     12.000000   \n",
       "no_of_credit_problems             0.145312      0.145312      1.000000   \n",
       "current_credit_balance        15439.198372  15439.198372   4993.000000   \n",
       "max_open_credit               40776.357186  40776.357186  14729.000000   \n",
       "bankruptcies                      0.105735      0.105735      1.000000   \n",
       "tax_liens                         0.000000      0.000000      0.000000   \n",
       "no_of_properties                  1.000000      2.000000      2.000000   \n",
       "no_of_cars                        2.490606      2.490606      4.000000   \n",
       "no_of_children                    1.501658      1.501658      0.000000   \n",
       "application_year               2015.000000   2015.000000   2015.000000   \n",
       "application_month                 1.000000      4.000000      2.000000   \n",
       "application_week                  2.000000     15.000000      7.000000   \n",
       "application_day                   6.000000      8.000000     10.000000   \n",
       "application_season                1.000000      2.000000      1.000000   \n",
       "current_credit_balance_ratio      0.000000      0.000000      0.627340   \n",
       "loan_status                       1.000000      1.000000      0.000000   \n",
       "\n",
       "                                         3             4  \n",
       "current_loan_amount           29346.000000   6011.000000  \n",
       "term                              1.000000      0.000000  \n",
       "credit_score                   1350.696132   1350.696132  \n",
       "years_in_current_job             -1.000000     -1.000000  \n",
       "home_ownership                    1.000000      1.000000  \n",
       "annual_income                 71612.920399  71612.920399  \n",
       "purpose                           0.786098      0.003407  \n",
       "monthly_debt                    941.224573    941.224573  \n",
       "years_of_credit_history          18.560949     18.560949  \n",
       "months_since_last_delinquent     34.752726     34.752726  \n",
       "no_of_open_accounts              11.028741     11.028741  \n",
       "no_of_credit_problems             0.145312      0.145312  \n",
       "current_credit_balance        15439.198372  15439.198372  \n",
       "max_open_credit               40776.357186  40776.357186  \n",
       "bankruptcies                      0.105735      0.105735  \n",
       "tax_liens                         0.000000      0.000000  \n",
       "no_of_properties                  2.000000      4.000000  \n",
       "no_of_cars                        2.490606      2.490606  \n",
       "no_of_children                    1.501658      1.501658  \n",
       "application_year               2015.000000   2015.000000  \n",
       "application_month                 2.000000      4.000000  \n",
       "application_week                  7.000000     16.000000  \n",
       "application_day                  10.000000     15.000000  \n",
       "application_season                1.000000      2.000000  \n",
       "current_credit_balance_ratio      0.000000      0.000000  \n",
       "loan_status                       1.000000      1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select specified predictor columns and the target column from tdf, \n",
    "# display the first five rows, and transpose the resulting DataFrame\n",
    "tdf[config.PREDICTORS + [config.TARGET]].head().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc358b73",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('Anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9054e5812adb29eebbcd6b680e8ef1afc4fe6e00a75ff130e735bd95b5b32301"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
